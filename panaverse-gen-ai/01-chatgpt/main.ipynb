{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the land of code, a technique so noble,\n",
      "A pattern of repetition, known as recursion.\n",
      "A function calling itself, a tale retold,\n",
      "In a loop of elegance, a story's evolution.\n",
      "\n",
      "Like a mirror reflecting its own reflection,\n",
      "Recursion calls upon itself without hesitation.\n",
      "Breaking down problems, with grace and finesse,\n",
      "Weaving through layers, with code's caress.\n",
      "\n",
      "In the realm of algorithms, it holds great might,\n",
      "Solving puzzles, unfolding with each recursive sight.\n",
      "A dance of iterations, a beautiful art,\n",
      "Unfolding patterns, written in the heart.\n",
      "\n",
      "But beware, dear coder, of infinite recurrence,\n",
      "A looping nightmare, a dreaded occurrence.\n",
      "For in the world of recursion, balance is key,\n",
      "To unlock its wonders, with mindful decree.\n",
      "\n",
      "So embrace the power, but wield it with care,\n",
      "Let recursion guide you, through the code's affair.\n",
      "A poetic dance, in the programmer's hand,\n",
      "Recursion, a marvel, in the digital land.\n"
     ]
    }
   ],
   "source": [
    "def chat_completion()-> str:\n",
    "    completion : openai.ChatCompletion = openai.ChatCompletion.create(\n",
    "        model = 'gpt-3.5-turbo-1106',\n",
    "        messages = [\n",
    "            {'role': 'system', 'content': 'You are a poetic assistant, skilled in explaining complex programming concepts in creative poetry'},\n",
    "            {'role': 'user', 'content':'Compose a poem that explains the concept of recursion in programming'}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "print(chat_completion())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the model return output in json format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"months\": [\"April\", \"June\", \"September\", \"November\"]\n",
      "}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# even the output is in the json format, the type of output is string\n",
    "# because the output of llm is always string\n",
    "response = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo-1106',\n",
    "    response_format={'type': 'json_object'},\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": \"List of months that have 30 days\"}\n",
    "            ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "print(type(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting the output of ChatGPT into JSON format offers several advantages:\n",
      "\n",
      "1. Structured data: JSON format provides a structured and easy-to-read representation of the output, making it more convenient for parsing and further processing.\n",
      "\n",
      "2. Interoperability: JSON is widely supported and can be easily integrated with a variety of programming languages and applications, making it easier to exchange information between different systems.\n",
      "\n",
      "3. Customization: JSON format allows for the inclusion of key-value pairs, which can be customized to include specific metadata or additional information in the output.\n",
      "\n",
      "4. Standardization: Using JSON format helps standardize the output format, making it easier for developers to understand and work with the output across different applications or use cases.\n",
      "\n",
      "Overall, converting the output of ChatGPT into JSON format can improve the ease of use, flexibility, and interoperability of the data.\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# even if you dont specify response format, it still will be string\n",
    "json_data = openai.ChatCompletion.create(\n",
    "    model = 'gpt-3.5-turbo-1106',\n",
    "    #response_format = {'type':'json_object'},\n",
    "    messages = [\n",
    "        {'role':'system', \"content\": \"You are a helpful assistant designed to output JSON format\"},\n",
    "        {'role':'user', \"content\": \"What are the advantages to convert the output of ChatGPT into JSON format\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(json_data.choices[0].message.content)\n",
    "print(type(json_data.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function\n",
    "import json\n",
    "\n",
    "def get_current_weather(location: str, unit: str = 'fahrenheit')-> str:\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if 'tokyo' in location.lower():\n",
    "        return json.dumps({'location':'Tokyo', \n",
    "                        'temperature': '10',\n",
    "                        'unit': 'celsius'})\n",
    "    elif 'san francisco' in location.lower():\n",
    "        return json.dumps({'location':'San francisco', \n",
    "                    'temperature': '72',\n",
    "                    'unit': 'fahrenheit'})\n",
    "    elif 'paris' in location.lower():\n",
    "        return json.dumps({'location':'Paris', \n",
    "                        'temperature': '22',\n",
    "                        'unit': 'celsius'})\n",
    "    else:\n",
    "        return json.dumps({'location':location, \n",
    "                        'temperature': 'unknown'})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(main_request: str)->str:\n",
    "    #Step 1: Send the conversation and available functions to the model\n",
    "    \n",
    "    messages = [{'role': 'user','content':main_request}] #user messages list\n",
    "    \n",
    "    #along with the prompt messages, we give details about the function\n",
    "    \n",
    "    tools=[#list of function to be passed along the prompt\n",
    "        { #first function to be passed along the prompt\n",
    "            'type':'function',# define what you are passing. Here it is function\n",
    "            'function':{ #what the function is\n",
    "                'name': 'get_current_weather', #name of the function\n",
    "                'description': 'Get the current weather in a give location',\n",
    "                #what the function is doing (important for NLP to understand \n",
    "                # what the function is used for)\n",
    "                'parameters': { #what is passed as argument to function\n",
    "                    'type': 'object',\n",
    "                    'properties':{\n",
    "                        'location': {#first parameter\n",
    "                            'type': 'string', #type of location parameter\n",
    "                            'description': 'The city and state e.g San Francisco, CA',\n",
    "                            #description of the parameter\n",
    "                        },\n",
    "                        'unit': { #second parameter\n",
    "                            'type':'string', #type of the unit parameter\n",
    "                            'enum': ['celsius', 'fahrenheit']\n",
    "                        }\n",
    "                    },\n",
    "                    'required': ['location'] #required parameter (if not \n",
    "                    #provided, the function will not run)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # First request\n",
    "    \n",
    "    response: openai.ChatCompletion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-1106\", #model selection\n",
    "        messages=messages, #message list\n",
    "        tools=tools, #list of dictionary to be passed\n",
    "        tool_choice=\"auto\",  # automatically select function that is to be used\n",
    "        #if general quesiton asked, it will respond with it's own knowledge\n",
    "        #but if asked particular question, it will auto call function\n",
    "    )\n",
    "    \n",
    "    response_message = response.choices[0].message\n",
    "    display(\"* First Response: \", dict(response_message))\n",
    "\n",
    "    \n",
    "    tool_calls = response_message.tool_calls #additional parameter\n",
    "    display(\"First Response Tool Calls: \", tool_calls) #give details about\n",
    "    #list of function that is to be called\n",
    "    \n",
    "    #Step 2: Check if the model wanted to call a function\n",
    "    \n",
    "    if tool_calls: #if the list have any element then what to do\n",
    "        #Step 3: Call the function. The JSON response may not always be correct\n",
    "        #Be sure to handle errors\n",
    "        \n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        } #\n",
    "        \n",
    "        messages.append(response_message)  \n",
    "        # extend conversation with assistant's reply\n",
    "        \n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name #extract the name of function\n",
    "            \n",
    "            function_to_call = available_functions[function_name] # check if the\n",
    "            # present in available_functions. If so, assign the function name\n",
    "            # to the variable\n",
    "            \n",
    "            function_args = json.loads(tool_call.function.arguments) #all the \n",
    "            #parameter of the function is converted into JSON (dictionary)\n",
    "            \n",
    "            function_response = function_to_call( \n",
    "                location=function_args.get(\"location\"),#get location parameter\n",
    "                unit=function_args.get(\"unit\"), #get unit parameter\n",
    "            )\n",
    "            \n",
    "            messages.append( #response after running custom function is appended\n",
    "                            #to the messages list (thread)\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id, #which function is running and\n",
    "                    #its id\n",
    "                    \"role\": \"tool\", #role of custom function (tool)\n",
    "                    \"name\": function_name, #name of custom function \n",
    "                    \"content\": function_response, #response of the custom function\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "            \n",
    "        display(\"* Second Request Messages: \", list(messages)) \n",
    "        \n",
    "        second_response: openai.ChatCompletion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function \n",
    "        #response\n",
    "        \n",
    "        print(\"* Second Response: \", dict(second_response))\n",
    "        \n",
    "        return second_response.choices[0].message.content\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* First Response: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'tool_calls': [<OpenAIObject id=call_9mVXmG2Tq7gygHKiHrrNgGMj at 0x2761eb786d0> JSON: {\n",
       "    \"id\": \"call_9mVXmG2Tq7gygHKiHrrNgGMj\",\n",
       "    \"type\": \"function\",\n",
       "    \"function\": {\n",
       "      \"name\": \"get_current_weather\",\n",
       "      \"arguments\": \"{\\\"location\\\": \\\"San Francisco\\\", \\\"unit\\\": \\\"celsius\\\"}\"\n",
       "    }\n",
       "  },\n",
       "  <OpenAIObject id=call_d3HL4bCS3SgZWRotzMoLW3FD at 0x2761eb78c20> JSON: {\n",
       "    \"id\": \"call_d3HL4bCS3SgZWRotzMoLW3FD\",\n",
       "    \"type\": \"function\",\n",
       "    \"function\": {\n",
       "      \"name\": \"get_current_weather\",\n",
       "      \"arguments\": \"{\\\"location\\\": \\\"Tokyo\\\", \\\"unit\\\": \\\"celsius\\\"}\"\n",
       "    }\n",
       "  },\n",
       "  <OpenAIObject id=call_hC0KZrJb67WIRwiHUblepU5t at 0x2761ea13740> JSON: {\n",
       "    \"id\": \"call_hC0KZrJb67WIRwiHUblepU5t\",\n",
       "    \"type\": \"function\",\n",
       "    \"function\": {\n",
       "      \"name\": \"get_current_weather\",\n",
       "      \"arguments\": \"{\\\"location\\\": \\\"Paris\\\", \\\"unit\\\": \\\"celsius\\\"}\"\n",
       "    }\n",
       "  }]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'First Response Tool Calls: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<OpenAIObject id=call_9mVXmG2Tq7gygHKiHrrNgGMj at 0x2761eb786d0> JSON: {\n",
       "   \"id\": \"call_9mVXmG2Tq7gygHKiHrrNgGMj\",\n",
       "   \"type\": \"function\",\n",
       "   \"function\": {\n",
       "     \"name\": \"get_current_weather\",\n",
       "     \"arguments\": \"{\\\"location\\\": \\\"San Francisco\\\", \\\"unit\\\": \\\"celsius\\\"}\"\n",
       "   }\n",
       " },\n",
       " <OpenAIObject id=call_d3HL4bCS3SgZWRotzMoLW3FD at 0x2761eb78c20> JSON: {\n",
       "   \"id\": \"call_d3HL4bCS3SgZWRotzMoLW3FD\",\n",
       "   \"type\": \"function\",\n",
       "   \"function\": {\n",
       "     \"name\": \"get_current_weather\",\n",
       "     \"arguments\": \"{\\\"location\\\": \\\"Tokyo\\\", \\\"unit\\\": \\\"celsius\\\"}\"\n",
       "   }\n",
       " },\n",
       " <OpenAIObject id=call_hC0KZrJb67WIRwiHUblepU5t at 0x2761ea13740> JSON: {\n",
       "   \"id\": \"call_hC0KZrJb67WIRwiHUblepU5t\",\n",
       "   \"type\": \"function\",\n",
       "   \"function\": {\n",
       "     \"name\": \"get_current_weather\",\n",
       "     \"arguments\": \"{\\\"location\\\": \\\"Paris\\\", \\\"unit\\\": \\\"celsius\\\"}\"\n",
       "   }\n",
       " }]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'* Second Request Messages: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"What's the weather like in San Francisco, Tokyo, and Paris?\"},\n",
       " <OpenAIObject at 0x2761eb78b30> JSON: {\n",
       "   \"role\": \"assistant\",\n",
       "   \"content\": null,\n",
       "   \"tool_calls\": [\n",
       "     {\n",
       "       \"id\": \"call_9mVXmG2Tq7gygHKiHrrNgGMj\",\n",
       "       \"type\": \"function\",\n",
       "       \"function\": {\n",
       "         \"name\": \"get_current_weather\",\n",
       "         \"arguments\": \"{\\\"location\\\": \\\"San Francisco\\\", \\\"unit\\\": \\\"celsius\\\"}\"\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"id\": \"call_d3HL4bCS3SgZWRotzMoLW3FD\",\n",
       "       \"type\": \"function\",\n",
       "       \"function\": {\n",
       "         \"name\": \"get_current_weather\",\n",
       "         \"arguments\": \"{\\\"location\\\": \\\"Tokyo\\\", \\\"unit\\\": \\\"celsius\\\"}\"\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"id\": \"call_hC0KZrJb67WIRwiHUblepU5t\",\n",
       "       \"type\": \"function\",\n",
       "       \"function\": {\n",
       "         \"name\": \"get_current_weather\",\n",
       "         \"arguments\": \"{\\\"location\\\": \\\"Paris\\\", \\\"unit\\\": \\\"celsius\\\"}\"\n",
       "       }\n",
       "     }\n",
       "   ]\n",
       " },\n",
       " {'tool_call_id': 'call_9mVXmG2Tq7gygHKiHrrNgGMj',\n",
       "  'role': 'tool',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '{\"location\": \"San francisco\", \"temperature\": \"72\", \"unit\": \"fahrenheit\"}'},\n",
       " {'tool_call_id': 'call_d3HL4bCS3SgZWRotzMoLW3FD',\n",
       "  'role': 'tool',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '{\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": \"celsius\"}'},\n",
       " {'tool_call_id': 'call_hC0KZrJb67WIRwiHUblepU5t',\n",
       "  'role': 'tool',\n",
       "  'name': 'get_current_weather',\n",
       "  'content': '{\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": \"celsius\"}'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Second Response:  {'id': 'chatcmpl-8kmP6H0tdxqfeBVK5o0Bh7fZgs7Cw', 'object': 'chat.completion', 'created': 1706159844, 'model': 'gpt-3.5-turbo-1106', 'choices': [<OpenAIObject at 0x2761ea12a70> JSON: {\n",
      "  \"index\": 0,\n",
      "  \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"The current weather in San Francisco is 72\\u00b0F and sunny, in Tokyo it is 10\\u00b0C and partly cloudy, and in Paris it is 22\\u00b0C and mostly sunny.\"\n",
      "  },\n",
      "  \"logprobs\": null,\n",
      "  \"finish_reason\": \"stop\"\n",
      "}], 'usage': <OpenAIObject at 0x2761ea129d0> JSON: {\n",
      "  \"prompt_tokens\": 170,\n",
      "  \"completion_tokens\": 36,\n",
      "  \"total_tokens\": 206\n",
      "}, 'system_fingerprint': 'fp_aaa20cc2ba'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current weather in San Francisco is 72°F and sunny, in Tokyo it is 10°C and partly cloudy, and in Paris it is 22°C and mostly sunny.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_conversation(\"What's the weather like in San Francisco, Tokyo, and Paris?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cryptocurrency_price(crypto: str)-> str:\n",
    "    '''Get crypto current price'''\n",
    "    if 'bitcoin' in crypto.lower():\n",
    "        return json.dumps({'crypto': 'Bitcoin', 'price': '40,016'})\n",
    "    elif 'ethereum'in crypto.lower():\n",
    "        return json.dumps({'crypto': 'Ethereum', 'price': '2,222'})\n",
    "    elif 'usdt' in crypto.lower():\n",
    "        return json.dumps({'crypto': 'USDT', 'price': '0.999'})\n",
    "    elif 'bnb' in crypto.lower():\n",
    "        return json.dumps({'crypto': 'BNB', 'price': '290.33'})\n",
    "    else:\n",
    "        return json.dumps({'crypto': crypto, 'price':'unknown'})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_conversation(main_request: str)->str:\n",
    "    \n",
    "    message_list = [{'role':'user', 'content':main_request}]\n",
    "    tools=[\n",
    "        {\n",
    "            'type':'function',\n",
    "            'function':{\n",
    "                'name':'get_cryptocurrency_price',\n",
    "                'description': 'Get current price of crypto currency',\n",
    "                'parameters':{\n",
    "                    'type': 'object',\n",
    "                    'properties':{\n",
    "                        'crypto':{\n",
    "                            'type': 'string',\n",
    "                            'description':'Name of the crypto currency to get current price'\n",
    "                        }\n",
    "                    },\n",
    "                    'required': ['crypto']\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = 'gpt-3.5-turbo-1106',\n",
    "        messages = message_list,\n",
    "        tools = tools,\n",
    "        tool_choice = 'auto'\n",
    "    )\n",
    "    \n",
    "    assistant_message = response.choices[0].message\n",
    "    tool_calls = assistant_message.tool_calls\n",
    "    \n",
    "    if tool_calls:\n",
    "        available_functions = {\n",
    "            'get_cryptocurrency_price': get_cryptocurrency_price,\n",
    "        }\n",
    "        \n",
    "        message_list.append(assistant_message)\n",
    "        \n",
    "        for tool_call in tool_calls:\n",
    "            \n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            function_response = function_to_call(\n",
    "                crypto = function_args.get('crypto')\n",
    "            )\n",
    "            \n",
    "            message_list.append({\n",
    "                'tool_call_id': tool_call.id,\n",
    "                'role':'tool',\n",
    "                'name': function_name,\n",
    "                'content': function_response\n",
    "            })\n",
    "        \n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model = 'gpt-3.5-turbo-1106',\n",
    "            messages = message_list,\n",
    "        )\n",
    "        \n",
    "        return second_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The price of Ethereum today is $2,222.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_price_conversation('What is the price of Ethereum today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The price of Bitcoin today is $40,016.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_price_conversation('What is the price of Bitcoin today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I couldn't find the current price of PKR.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_price_conversation('What is the price of PKR today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "tool_calls",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\Web 3.0\\Generative AI\\Anaconda\\envs\\py10\\lib\\site-packages\\openai\\openai_object.py:59\u001b[0m, in \u001b[0;36mOpenAIObject.__getattr__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tool_calls'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_price_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWhat the R&B music genre means?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 33\u001b[0m, in \u001b[0;36mget_price_conversation\u001b[1;34m(main_request)\u001b[0m\n\u001b[0;32m     25\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     26\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-1106\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     27\u001b[0m     messages \u001b[38;5;241m=\u001b[39m message_list,\n\u001b[0;32m     28\u001b[0m     tools \u001b[38;5;241m=\u001b[39m tools,\n\u001b[0;32m     29\u001b[0m     tool_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m assistant_message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m---> 33\u001b[0m tool_calls \u001b[38;5;241m=\u001b[39m \u001b[43massistant_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_calls\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tool_calls:\n\u001b[0;32m     36\u001b[0m     available_functions \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_cryptocurrency_price\u001b[39m\u001b[38;5;124m'\u001b[39m: get_cryptocurrency_price,\n\u001b[0;32m     38\u001b[0m     }\n",
      "File \u001b[1;32md:\\Web 3.0\\Generative AI\\Anaconda\\envs\\py10\\lib\\site-packages\\openai\\openai_object.py:61\u001b[0m, in \u001b[0;36mOpenAIObject.__getattr__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[k]\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;241m*\u001b[39merr\u001b[38;5;241m.\u001b[39margs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: tool_calls"
     ]
    }
   ],
   "source": [
    "get_price_conversation('What the R&B music genre means?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
